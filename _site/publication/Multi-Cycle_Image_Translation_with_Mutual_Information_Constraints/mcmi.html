
<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>
<script type="text/javascript" src="http://latex.codecogs.com/latexit.js"></script>
<script type="text/javascript">
LatexIT.add('p',true);
</script>
<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}
	
	h1 {
		font-size:30px;
		font-weight:300;
	}
	
	.disclaimerbox {
		background-color: #eee;		
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}
	
	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}
	
	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		        15px 15px 0 0px #fff, /* The fourth layer */
		        15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		        20px 20px 0 0px #fff, /* The fifth layer */
		        20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		        25px 25px 0 0px #fff, /* The fifth layer */
		        25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}
	
	.vert-cent {
		position: relative;
	    top: 50%;
	    transform: translateY(-50%);
	}
	
	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>

<html>
  <head>
		<title>MCMI: Multi-Cycle Image Translation with Mutual Information Constraints</title>
		<meta property="og:title" content="MCMI: Multi-Cycle Image Translation with Mutual Information Constraints." />
		<!-- <meta property="og:description" content="Under Submission." /> -->

		<!-- Global site tag (gtag.js) - Google Analytics -->
		<script async src="https://www.googletagmanager.com/gtag/js?id=UA-75863369-6"></script>
		<script>
		  window.dataLayer = window.dataLayer || [];
		  function gtag(){dataLayer.push(arguments);}
		  gtag('js', new Date());

		  gtag('config', 'UA-75863369-6');
		</script>
  </head>

  <body>
    <br>
          <center>
          	<span style="font-size:34px">MCMI: Multi-Cycle Image Translation with Mutual Information Constraints</span>
	  		  <table align=center width=750px>
	  			  <tr>
	  	              <td align=center width=100px>
	  					<center>
                                                <span style="font-size:18px">
                                                    <a href="https://samxuxiang.github.io/">Xiang Xu</a> &nbsp;&nbsp;&nbsp;&nbsp;  
                                                    <a href="http://www.sfu.ca/~mnawhal/">Megha Nawhal</a> &nbsp;&nbsp;&nbsp;&nbsp; 
                                                    <a href="https://www.cs.sfu.ca/~mori/">Greg Mori</a> &nbsp;&nbsp;&nbsp;&nbsp;
                                                    <a href="https://msavva.github.io/">Manolis Savva</a> 
                                                </span><br>
		  		  		</center>
		  		  	  </td>

		  		  </tr>
	  			  <tr>
		  		  </tr>
			  </table>
          </center>
          <p style="margin-bottom:0.5cm;"><br></p>
          <center>
  		  <table align=center width=750px>
  			  <tr>
  					<center>
  	                	<img class="round" style="width:800px" src="./teaser.png"/>
	  				</center>
  	              </td>
  		  </table>
  		</center>

          <hr>
          

  		  <table align=center width=800px>
	  		  <center><h1>Abstract</h1></center>
	  		  <tr>
	  		  	<td>
                    We present a mutual information-based framework for unsupervised image-to-image translation. 
                    Our MCMI approach treats single-cycle image translation
                    models as modules that can be used recurrently in a multi-cycle translation setting
                    where the translation process is bounded by mutual information constraints between
                    the input and output images. The proposed mutual information constraints can
                    improve cross-domain mappings by optimizing out translation functions that fail
                    to satisfy the Markov property during image translations. We show that models
                    trained with MCMI produce images with increased quality and more semantically-relevant 
                    mappings compared to state-of-the-art image translation methods. The
                    MCMI framework can be applied to existing unpaired image-to-image translation
                    models with minimum modifications. Qualitative experiments and a perceptual
                    study demonstrate the image quality improvements and generality of our approach
                    using several backbone models and a variety of image datasets.
	  		    </td>
	  		  </tr>
			</table>

<!--  		  <br>
		  <hr>

  		  <table align=center width=450px>
	  		  <center><h1>Method overview</h1></center>
  			  <tr>
  	              <td align=center width=400px>
  					<center>
						  <td><img class="round" style="width:380px" src="./zs_hoi_generation/resources/model_overview.png"/></td>
	  		  		</center>
			  </tr>

		  </center>
		  </table>
  		  <table align=center width=800px>
		  	<center>
		  		<tr>
		  			<td>
                                <p>We propose an adversarial learning scheme in which we train a generator network $\mathbf{G}$ with a set of 4 discriminators: (1) a frame discriminator $\mathbf{D}_f$, which encourages the generator to learn spatially coherent visual content; (2) a gradient discriminator $\mathbf{D}_g$, which incentivizes $\mathbf{G}$ to produce temporally consistent frames; (3) a video discriminator $\mathbf{D}_v$, which provides the generator with global spatio-temporal context; and (4) a relational discriminator $\mathbf{D}_r$, which assists the generator in producing right object layouts in a video. We use pretrained word embeddings for semantic representations of actions and objects. All discriminators are conditioned on word embeddings of the action ($\mathbf{s}_a$) and object ($\mathbf{s}_o$) and trained simultaneously in an end-to-end manner.</p>	
		  			</td>
		  		</tr>
		  </center>
		  </table>
		  <br>

		  <hr>
        <center><h1>Video</h1></center>
        <p align="center">
        <video width="660" height="395" controls>
           <source src="zs_hoi_generation/resources/zs_hoi_generation.mp4" type="video/mp4">
         </video>
      	  <br>
		  <hr>
-->

  		 <br>
		<hr>
		<br>
  		  <!-- <table align=center width=550px> -->
  		  <table align=center width=800px>
	 		<center><h1>Paper and Supplementary Material</h1></center>
  			  <tr>
				  <td><a href="https://arxiv.org/abs/2007.02919"><img class="layered-paper-big" style="height:160px" src="./paper.png"/></a></td>
				  <td><span style="font-size:12pt">
				  <b>MCMI: Multi-Cycle Image Translation with Mutual Information Constraints. </b><br>
                                   X. Xu, M. Nawhal, G. Mori, M. Savva<br>
				  <a href="https://arxiv.org/abs/2007.02919">[arXiv]</a><br>
				  <span style="font-size:4pt"><a href=""><br></a>
				  </span>
				  </td>
  	              </td>
              </tr>
  		  </table>
		  <br>
		  <br>
          <hr>


		  <center><h1>Code</h1></center>
		  <table align=center width=1000px>
			  <tr>
					  <center>
						<a href="https://github.com/samxuxiang/mcmi"><img class="round" style="height:250" src="./mcmi_overview.png"/></a>
					  </center>
			</tr>
		</table>

		  <table align=center width=800px>
			<tr><center> <br>
			  <span style="font-size:20px">&nbsp;<a href='https://github.com/samxuxiang/mcmi'>[GitHub]</a>

			  <span style="font-size:20px"></a></span>
			<br>
			</center></tr>
		</table>
		  <br>


            
             <br>
             <hr>
            <br>
        <table style="font-size:11px" align=center>
        <tr>
        <td>
            Template borrowed from <a href='https://richzhang.github.io/colorization/'>Richard Zhang</a>.
        </td>
        </tr>
        </table> 
</body>
</html>
 
